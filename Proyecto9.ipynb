{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente proyecto trataré de dar solución al problema del banco Beta Bank el cual consiste en la preocupante perdida de clientes conforme pasa el tiempo, para esto se nos pide crear un modelo que pueda predecir los clientes del banco que estan más propensos a salirse para implementar un método de retención y lograr que estos clientes no abandonen el banco.\n",
    "\n",
    "Nuestro objetivo en el modelo es lograr el máximo valor F1 posible, teniendo como mínimo un valor de al menos 0.59 con la base de datos proporcionada del banco Beta Bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Librerías y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración Inicial de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente sección luego de haber cargado las librerías necesarias y de haber importado los datos del archivo csv, porocederé a hacer un análisis exploratorio inicial para hacer un sondeo de la base de datos y ver si todo es correcto para proceder con la creación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de Columnas Descartables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de hacer un análisis inicial pude observar que para nuestro enfoque en la creación de un modelo de predicción las columnas RowNumber, CustomerId y Surname a pesar de ser numéricas no aportan ningún beneficio al modelado e incluso a mi punto de ver pueden causar alguna confusión, por eso en el siguiente paso las eliminaré, además pude observar que existen algunos valores ausentes los cuales manejaré más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al hacer el análisis exploratorio de datos me di cuenta que la variable \"Tenure\" tenía valores ausentes y para poder continuar con la creación del modelo debo arreglar esta situación primero, esto se puede hacer a través de distintos métodos como completar con el valor promedio, completar con el valor mediano, rellenar en función de otras variables o rellenar con valor 0 qe en este caso es el método que decidí escoger para solucionar este problema.\n",
    "\n",
    "Escogí rellenar con el valor 0 los valores ausentes porque esto indica que los clientes con ese valor aun no han hecho un año en el banco, es decir como si fueran clientes nuevos al igual que otra parte de la base de datos en donde sí vienen indicados varios clientes con 0 que dan a entender que son nuevos y de esta manera en mi opinión, no se perjuduca tanto a las estadísticas originales que nos aporta la base de datos, ya que considero que los otros metódos son mas agresivos y podrían causar alguna distorción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     1291\n",
       "1.0      952\n",
       "2.0      950\n",
       "3.0      928\n",
       "4.0      885\n",
       "5.0      927\n",
       "6.0      881\n",
       "7.0      925\n",
       "8.0      933\n",
       "9.0      882\n",
       "10.0     446\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].fillna(0, inplace=True)\n",
    "\n",
    "df['Tenure'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguinte parte del proyecto voy a analizar las variables categóricas para ver de que manera las puedo manejar y continuar con la creación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analisar observé que las columnas Gender y Geography son las únicas que se pueden considerar como categóricas por lo cual utilizaré el código preprocessing de la librería sklearn para transformar su contenido en valores numéricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography: ['France' 'Spain' 'Germany']\n",
      "Geography: [0 2 1]\n",
      "Gender: ['Female' 'Male']\n",
      "Gender: [0 1]\n"
     ]
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    \n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "    label_encoder.fit(df[col].unique())\n",
    " \n",
    "    df[col] = label_encoder.transform(df[col])\n",
    "\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42     2.0       0.00              1   \n",
       "1          608          2       0   41     1.0   83807.86              1   \n",
       "2          502          0       0   42     8.0  159660.80              3   \n",
       "3          699          0       0   39     1.0       0.00              2   \n",
       "4          850          2       0   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División en Conjuntos de Entrenamiento y de Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección dividiré los datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 7083\n",
      "Tamaño del conjunto de prueba: 1500\n",
      "Tamaño del conjunto de validación: 1417\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.75\n",
    "val_ratio = 0.15 \n",
    "test_ratio = 0.15\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=test_ratio, random_state=42)\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size=val_ratio/(train_ratio+val_ratio), random_state=42)\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_data))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(test_data))\n",
    "print(\"Tamaño del conjunto de validación:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_data.drop(\"Exited\", axis=1)\n",
    "target_train = train_data[\"Exited\"]\n",
    "\n",
    "features_test = test_data.drop(\"Exited\", axis=1)\n",
    "target_test = test_data[\"Exited\"]\n",
    "\n",
    "features_valid = val_data.drop(\"Exited\", axis=1)\n",
    "target_valid = val_data[\"Exited\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del Equilibrio de Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección haré un análisis del equilibrio de las clases en el conjunto de entrenamiento y validación con el objetivo de verificar si hay un desequilibrio significativo entre las clases positivas que son los clientes que abandonaron el banco y las clases negativas que son los clientes que permanecieron en el banco.\n",
    "\n",
    "Con este análisis se tendrá una comprensión inicial de la distribución de los datos y así poder tomar decisiones más precisas al construir y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrio de las clases en el conjunto de entrenamiento:\n",
      "0    0.796979\n",
      "1    0.203021\n",
      "Name: Exited, dtype: float64\n",
      "Equilibrio de las clases en el conjunto de validación:\n",
      "0    0.784051\n",
      "1    0.215949\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Equilibrio de las clases en el conjunto de entrenamiento:\")\n",
    "print(target_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"Equilibrio de las clases en el conjunto de validación:\")\n",
    "print(target_valid.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar el equilibrio de las clases en el conjunto de entrenamiento, se puede observar que la proporción de clases es de aproximadamente el 79.6% para la Clase 0 que son los clientes que no abandonaron el banco y el 20.3% para la Clase 1 que son los clientes que abandonaron el banco mientras que en el conjunto de validación las proporciones son de alrededor del 78.4% para la clase 0 y el 21.5% para la Clase 1, estos resultados indican que hay un cierto desequilibrio en las clases con la clase 0 predominante en ambos conjuntos.\n",
    "\n",
    "Esto es importante para nuestro proyecto, ya que el desequilibrio de clases puede afectar el rendimiento del modelo porque  puede ser sesgado a favor de la clase mayoritaria por lo cual trataré con ello más adelante para evitar problemas en el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción del Modelo Inicial (sin considerar el desequilibrio de clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88      1111\n",
      "           1       0.49      0.06      0.10       306\n",
      "\n",
      "    accuracy                           0.78      1417\n",
      "   macro avg       0.64      0.52      0.49      1417\n",
      "weighted avg       0.72      0.78      0.71      1417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "print(classification_report(target_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del desempeño del modelo inicial: Al observar estos resultados se puede ver que el modelo obtuvo una alta precisión para la clase 0 que son los clientes que no se fueron y una baja precisión para la clase 1 que son los clientes que se fueron, además, el recall de la clase 1 y el valor F1 también son bajos, todo esto indica que el modelo tiene dificultades para identificar correctamente a los clientes que se han ido y por lo tanto tiene un mal rendimiento para predecir a los clientes que abandonarán el banco, en las siguientes secciones haré cambios para mejorar el modelo y obtener un buen rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejora del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección me centraré en mejorar el rendimiento del modelo inicial, equilibraré los atributos numéricos para garantizar que los valores de diferentes escalas tengan la misma importancia en el modelo y tendré en cuenta el desequilibrio de clase presente en los datos aplicando diferentes técnicas para corregir este desequilibrio y así poder evaluar el impacto de estos enfoques en el rendimiento general del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>-0.575693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.661804</td>\n",
       "      <td>-0.494656</td>\n",
       "      <td>0.335315</td>\n",
       "      <td>0.805116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>-0.296070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379897</td>\n",
       "      <td>-1.137115</td>\n",
       "      <td>-1.213746</td>\n",
       "      <td>0.805116</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>-0.523911</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474597</td>\n",
       "      <td>-0.173427</td>\n",
       "      <td>-1.213746</td>\n",
       "      <td>0.805116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.720708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>-1.507767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.895098</td>\n",
       "      <td>1.111491</td>\n",
       "      <td>0.694801</td>\n",
       "      <td>0.805116</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.224689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>-0.948522</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.135305</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.788407</td>\n",
       "      <td>-0.923480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender       Age    Tenure   Balance  \\\n",
       "6252    -0.575693          1       1 -0.661804 -0.494656  0.335315   \n",
       "4684    -0.296070          0       1  0.379897 -1.137115 -1.213746   \n",
       "1731    -0.523911          2       0  0.474597 -0.173427 -1.213746   \n",
       "4742    -1.507767          1       1  1.895098  1.111491  0.694801   \n",
       "4521    -0.948522          2       0 -1.135305  0.790262  0.788407   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "6252       0.805116          0               0        -1.011739  \n",
       "4684       0.805116          1               1         0.803046  \n",
       "1731       0.805116          1               0        -0.720708  \n",
       "4742       0.805116          1               1         1.224689  \n",
       "4521      -0.923480          1               1         0.252846  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric=['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrección del Desequilibrio de Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección aplicaré las técnicas de sobremuestreo y la submuestreo para corregir el desequilibrio de clases ya que estas nos ayudarán a equilibrar la representación de las clases minoritarias y mayoritarias mejorando la capacidad del modelo para aprender de manera efectiva de los datos disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrio de clases después del sobremuestreo:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat([features_train, target_train], axis=1)\n",
    "\n",
    "train_data_majority = train_data[train_data['Exited'] == 0]\n",
    "train_data_minority = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "train_data_minority_oversampled = train_data_minority.sample(n=len(train_data_majority), replace=True, random_state=42)\n",
    "\n",
    "train_data_combined = pd.concat([train_data_majority, train_data_minority_oversampled])\n",
    "\n",
    "features_train_oversampled = train_data_combined.drop(\"Exited\", axis=1)\n",
    "target_train_oversampled = train_data_combined[\"Exited\"]\n",
    "\n",
    "print(\"Equilibrio de clases después del sobremuestreo:\")\n",
    "print(target_train_oversampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación después del sobremuestreo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.79      1111\n",
      "           1       0.39      0.69      0.50       306\n",
      "\n",
      "    accuracy                           0.70      1417\n",
      "   macro avg       0.64      0.70      0.64      1417\n",
      "weighted avg       0.78      0.70      0.72      1417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_oversampled = LogisticRegression()\n",
    "model_oversampled.fit(features_train_oversampled, target_train_oversampled)\n",
    "predictions_oversampled = model_oversampled.predict(features_valid)\n",
    "\n",
    "print(\"Informe de clasificación después del sobremuestreo:\")\n",
    "print(classification_report(target_valid, predictions_oversampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los resultados de antes y después del sobremuestreo se puede observar una mejora en las métricas de recall y F1 para la clase minoritaria que en este caso es la clase 1, lo que indica que el modelo puede identificar mejor los ejemplos de esta clase pero como contra podemos ver que la precisión del modelo disminuyó después de aplicar el sobremuestreo, sin embargo, a pesar de esto se puede decir que hubo una mejora pero probaré en el siguiente bloque con el submuestreo para ver si arroja aún mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrio de clases después del submuestreo:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat([features_train, target_train], axis=1)\n",
    "\n",
    "train_data_majority = train_data[train_data['Exited'] == 0]\n",
    "train_data_minority = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "train_data_majority_undersampled = train_data_majority.sample(n=len(train_data_minority), random_state=42)\n",
    "\n",
    "train_data_combined = pd.concat([train_data_majority_undersampled, train_data_minority])\n",
    "\n",
    "features_train_undersampled = train_data_combined.drop(\"Exited\", axis=1)\n",
    "target_train_undersampled = train_data_combined[\"Exited\"]\n",
    "\n",
    "print(\"Equilibrio de clases después del submuestreo:\")\n",
    "print(target_train_undersampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación después del submuestreo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79      1111\n",
      "           1       0.40      0.70      0.51       306\n",
      "\n",
      "    accuracy                           0.71      1417\n",
      "   macro avg       0.65      0.71      0.65      1417\n",
      "weighted avg       0.79      0.71      0.73      1417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_undersampled = LogisticRegression()\n",
    "model_undersampled.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "predictions_undersampled = model_undersampled.predict(features_valid)\n",
    "\n",
    "report_undersampled = classification_report(target_valid, predictions_undersampled)\n",
    "print(\"Informe de clasificación después del submuestreo:\")\n",
    "print(report_undersampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar el submuestreo se puede observar que las estadísticas son aún mejores con esta técnica que con la de sobremuestreo, aunque ambas mejoran el modelo inicial sin considerar el desequilibrio de clases, el modelo de submuestreo es el que arroja mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección del Mejor Modelo y Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de abordar el desequilibrio de clases, trataré de seleccionar el mejor modelo y los mejores parámetros al intentar diferentes modelos como regresión logística, árbol de decisión y random forest, además, ajustaré sus parámetros para obtener el mejor rendimiento posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación del método de regresión logística:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1111\n",
      "           1       0.40      0.70      0.51       306\n",
      "\n",
      "    accuracy                           0.71      1417\n",
      "   macro avg       0.65      0.71      0.65      1417\n",
      "weighted avg       0.79      0.71      0.74      1417\n",
      "\n",
      "Mejores parámetros de regresión logística:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "     'C': [0.1, 1, 10],\n",
    "     'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear'],\n",
    "     'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='f1')\n",
    "\n",
    "grid_search.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "best_model_lr = grid_search.best_estimator_\n",
    "best_params_lr = grid_search.best_params_\n",
    "\n",
    "best_model_lr.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "predictions_best_lr = best_model_lr.predict(features_valid)\n",
    "\n",
    "report_best_lr = classification_report(target_valid, predictions_best_lr)\n",
    "print(\"Informe de clasificación del método de regresión logística:\")\n",
    "print(report_best_lr)\n",
    "\n",
    "print(\"Mejores parámetros de regresión logística:\")\n",
    "print(best_params_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación del árbol de decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80      1111\n",
      "           1       0.42      0.77      0.54       306\n",
      "\n",
      "    accuracy                           0.72      1417\n",
      "   macro avg       0.67      0.74      0.67      1417\n",
      "weighted avg       0.81      0.72      0.74      1417\n",
      "\n",
      "Los mejores parámetros del árbol de decisión:\n",
      "{'class_weight': 'balanced', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "     'max_depth': np.linspace(1, 20, 20, dtype=int),\n",
    "     'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='f1')\n",
    "\n",
    "grid_search.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "best_model_dt = grid_search.best_estimator_\n",
    "best_params_dt = grid_search.best_params_\n",
    "\n",
    "best_model_dt.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "predictions_best_dt = best_model_dt.predict(features_valid)\n",
    "\n",
    "report_best_dt = classification_report(target_valid, predictions_best_dt)\n",
    "print(\"Informe de clasificación del árbol de decisión:\")\n",
    "print(report_best_dt)\n",
    "\n",
    "print(\"Los mejores parámetros del árbol de decisión:\")\n",
    "print(best_params_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 7 : \n",
      "train: 0.8661584074544685\n",
      "valid: 0.858151023288638\n",
      "trainB: 0.8341098404630806\n",
      "validB: 0.8009880028228652\n",
      "\n",
      "depth 8 : \n",
      "train: 0.8749117605534378\n",
      "valid: 0.8652081863091038\n",
      "trainB: 0.8566991387830015\n",
      "validB: 0.8165137614678899\n",
      "\n",
      "depth 9 : \n",
      "train: 0.8850769447974022\n",
      "valid: 0.8645024700070572\n",
      "trainB: 0.8831003811944091\n",
      "validB: 0.8193366266760762\n",
      "\n",
      "depth 10 : \n",
      "train: 0.9008894536213469\n",
      "valid: 0.8659139026111503\n",
      "trainB: 0.9114781872088098\n",
      "validB: 0.8390966831333804\n",
      "\n",
      "depth 11 : \n",
      "train: 0.9167019624452916\n",
      "valid: 0.8715596330275229\n",
      "trainB: 0.9442326697726952\n",
      "validB: 0.8461538461538461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(7, 12):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth)\n",
    "        model.fit(features_train,target_train)\n",
    "        \n",
    "        train_predictions = model.predict(features_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        \n",
    "        modelb = RandomForestClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n",
    "        modelb.fit(features_train,target_train)\n",
    "        \n",
    "        train_predictionsb = modelb.predict(features_train)\n",
    "        predictions_validb = modelb.predict(features_valid)\n",
    "        \n",
    "        print( 'depth', depth, \": \")\n",
    "        print('train:',accuracy_score(target_train, train_predictions))\n",
    "        print('valid:',accuracy_score(target_valid, predictions_valid))\n",
    "        print('trainB:',accuracy_score(target_train, train_predictionsb))\n",
    "        print('validB:',accuracy_score(target_valid, predictions_validb))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del modelo de random forest en el conjunto de sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación de random forest sobremuestreado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      1111\n",
      "           1       0.58      0.69      0.63       306\n",
      "\n",
      "    accuracy                           0.83      1417\n",
      "   macro avg       0.75      0.78      0.76      1417\n",
      "weighted avg       0.84      0.83      0.83      1417\n",
      "\n",
      "Los mejores parámetros de random forest sobremuestreado:\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       random_state=12345)\n",
      "\n",
      "Resultado de la puntuación F1 en random forest sobremuestreado:\n",
      "0.6326836581709145\n"
     ]
    }
   ],
   "source": [
    "best_model_rf_oversample = RandomForestClassifier(random_state=12345, max_depth=10, class_weight='balanced')\n",
    "best_model_rf_oversample.fit(features_train_oversampled, target_train_oversampled)\n",
    "\n",
    "predicted_valid = best_model_rf_oversample.predict(features_valid)\n",
    "\n",
    "report_best_rf = classification_report(target_valid, predicted_valid)\n",
    "print(\"Informe de clasificación de random forest sobremuestreado:\")\n",
    "print(report_best_rf)\n",
    "\n",
    "print(\"Los mejores parámetros de random forest sobremuestreado:\")\n",
    "print(best_model_rf_oversample)\n",
    "print()\n",
    "print(\"Resultado de la puntuación F1 en random forest sobremuestreado:\")\n",
    "print(f1_score(target_valid,predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del modelo Random Forest en el conjunto de submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación de random forest submuestreado\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84      1111\n",
      "           1       0.49      0.77      0.60       306\n",
      "\n",
      "    accuracy                           0.77      1417\n",
      "   macro avg       0.71      0.77      0.72      1417\n",
      "weighted avg       0.83      0.77      0.79      1417\n",
      "\n",
      "Los mejores parámetros de random forest submuestreado:\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       random_state=12345)\n",
      "\n",
      "Resultado de la puntuación F1 en random forest submuestreado:\n",
      "0.5967130214917825\n"
     ]
    }
   ],
   "source": [
    "best_model_rf_undersample = RandomForestClassifier(random_state=12345, max_depth=10, class_weight='balanced')\n",
    "best_model_rf_undersample.fit(features_train_undersampled, target_train_undersampled)\n",
    "\n",
    "predicted_valid = best_model_rf_undersample.predict(features_valid)\n",
    "\n",
    "report_best_rf = classification_report(target_valid, predicted_valid)\n",
    "print(\"Informe de clasificación de random forest submuestreado\")\n",
    "print(report_best_rf)\n",
    "\n",
    "print(\"Los mejores parámetros de random forest submuestreado:\")\n",
    "print(best_model_rf_undersample)\n",
    "print()\n",
    "print(\"Resultado de la puntuación F1 en random forest submuestreado:\")\n",
    "print(f1_score(target_valid,predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del modelo Random Forest en el conjunto desequilibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación de random forest desequilibrado\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1111\n",
      "           1       0.62      0.64      0.63       306\n",
      "\n",
      "    accuracy                           0.84      1417\n",
      "   macro avg       0.76      0.77      0.77      1417\n",
      "weighted avg       0.84      0.84      0.84      1417\n",
      "\n",
      "Los mejores parámetros de random forest desequilibrado:\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       random_state=12345)\n",
      "\n",
      "Resultado de la puntuación F1 en random forest desequilibrado:\n",
      "0.6334405144694534\n"
     ]
    }
   ],
   "source": [
    "best_model_rf_unbalanced = RandomForestClassifier(random_state=12345, max_depth=10, class_weight='balanced')\n",
    "best_model_rf_unbalanced.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = best_model_rf_unbalanced.predict(features_valid)\n",
    "\n",
    "report_best_rf = classification_report(target_valid, predicted_valid)\n",
    "print(\"Informe de clasificación de random forest desequilibrado\")\n",
    "print(report_best_rf)\n",
    "\n",
    "print(\"Los mejores parámetros de random forest desequilibrado:\")\n",
    "print(best_model_rf_unbalanced)\n",
    "print()\n",
    "print(\"Resultado de la puntuación F1 en random forest desequilibrado:\")\n",
    "print(f1_score(target_valid,predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar varios intentos con diferentes modelos y despúes de analizar los resultados de cada uno, considero que el modelo que obtuvo mejores resultados fue el modelo de random forest en el conjunto desequilibrado dado que resulto un valor F1 de 0.63 y una precisión del 0.84 aproximadamente, por eso escogeré este modelo para continuar con el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del Rendimiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evaluaremos el rendimiento del modelo utilizando métricas como precisión, recall, F1 y AUC-ROC y compararemos estas métricas con las obtenidas por el modelo anterior para evaluar si hay mejoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación del mejor modelo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1111\n",
      "           1       0.62      0.64      0.63       306\n",
      "\n",
      "    accuracy                           0.84      1417\n",
      "   macro avg       0.76      0.77      0.77      1417\n",
      "weighted avg       0.84      0.84      0.84      1417\n",
      "\n",
      "AUC-ROC del mejor modelo: 0.768\n",
      "\\Informe de calificación del modelo: inicial\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88      1111\n",
      "           1       0.49      0.06      0.10       306\n",
      "\n",
      "    accuracy                           0.78      1417\n",
      "   macro avg       0.64      0.52      0.49      1417\n",
      "weighted avg       0.72      0.78      0.71      1417\n",
      "\n",
      "AUC-ROC del modelo inicial: 0.520\n",
      "\n",
      "Comparación de métricas de rendimiento:\n",
      " Initial Model | Best Model\n",
      "Precision (class 0):      0.791 |      0.901\n",
      "Recall (class 0):      0.984 |      0.893\n",
      "F1-score (class 0):      0.877 |      0.897\n",
      "Accuracy (class 1):      0.486 |      0.623\n",
      "Recall (class 1):      0.056 |      0.644\n",
      "F1-score (class 1):      0.100 |      0.633\n",
      "AUC-ROC:      0.520 |      0.768\n"
     ]
    }
   ],
   "source": [
    "predictions_best = best_model_rf_unbalanced.predict(features_valid)\n",
    "\n",
    "report_best = classification_report(target_valid, predictions_best, output_dict=True)\n",
    "auc_roc_best = roc_auc_score(target_valid, predictions_best)\n",
    "\n",
    "print(\"Informe de clasificación del mejor modelo:\")\n",
    "print(classification_report(target_valid, predictions_best))\n",
    "print(\"AUC-ROC del mejor modelo: {:.3f}\".format(auc_roc_best))\n",
    "\n",
    "report_initial = classification_report(target_valid, predictions, output_dict=True)\n",
    "auc_roc_initial = roc_auc_score(target_valid, predictions)\n",
    "\n",
    "print(\"\\Informe de calificación del modelo: inicial\")\n",
    "print(classification_report(target_valid, predictions))\n",
    "print(\"AUC-ROC del modelo inicial: {:.3f}\".format(auc_roc_initial))\n",
    "\n",
    "print(\"\\nComparación de métricas de rendimiento:\")\n",
    "print(\" Initial Model | Best Model\")\n",
    "print(\"Precision (class 0): {:10.3f} | {:10.3f}\".format(report_initial[\"0\"][\"precision\"], report_best[\"0\"][\"precision\"]))\n",
    "print(\"Recall (class 0): {:10.3f} | {:10.3f}\".format(report_initial[\"0\"][\"recall\"], report_best[\"0\"][\"recall\"]))\n",
    "print(\"F1-score (class 0): {:10.3f} | {:10.3f}\".format(report_initial[\"0\"][\"f1-score\"], report_best[\"0\"][\"f1-score\"]))\n",
    "print(\"Accuracy (class 1): {:10.3f} | {:10.3f}\".format(report_initial[\"1\"][\"precision\"], report_best[\"1\"][\"precision\"]))\n",
    "print(\"Recall (class 1): {:10.3f} | {:10.3f}\".format(report_initial[\"1\"][\"recall\"], report_best[\"1\"][\"recall\"]))\n",
    "print(\"F1-score (class 1): {:10.3f} | {:10.3f}\".format(report_initial[\"1\"][\"f1-score\"], report_best[\"1\"][\"f1-score\"]))\n",
    "print(\"AUC-ROC: {:10.3f} | {:10.3f}\".format(auc_roc_initial, auc_roc_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar los resultados puedo decir que, en general, el  modelo mejorado tuvo un mejor rendimiento que el modelo inicial sólo hubo una mínima disminución en la recuperación de la clase 0 pero logro mejoras en todos los otros apartados incluso logró una puntuación AUC-ROC mayor por eso deduzco que el modelo mejorado es más equilibrado y capaz de ayudarnos a lograr el objetivo planteado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Final y Aplicación del Modelo al Conjunto de Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar el modelo al conjunto de pruebas utilizaré la función de predicción del mejor modelo entrenado, pasando como entrada las variables independientes del conjunto de pruebas y  luego compararé las predicciones obtenidas con las clases reales del conjunto de pruebas para evaluar el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_rf = best_model_rf_unbalanced.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del valor F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación calcularé el valor F1 para el conjunto de prueba, comparando las predicciones del modelo con las etiquetas reales y almacenando el valor F1 en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 value: 0.624\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(target_test, predictions_test_rf)\n",
    "\n",
    "print(\"F1 value: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de Métricas AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calcularé la métrica AUC-ROC para el conjunto de prueba comparando las predicciones del modelo con las etiquetas reales y almacenando la puntuación AUC-ROC en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.774\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(target_test, predictions_test_rf)\n",
    "\n",
    "print(\"AUC-ROC: {:.3f}\".format(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación del valor F1 con el requisito mínimo y comparación de la métrica AUC-ROC con el modelo inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor F1 cumple el requisito mínimo de 0.59.\n",
      "Se ha mejorado la métrica AUC-ROC con respecto al modelo inicial.\n"
     ]
    }
   ],
   "source": [
    "if f1 >= 0.59:\n",
    "     print(\"El valor F1 cumple el requisito mínimo de 0.59.\")\n",
    "else:\n",
    "     print(\"El valor F1 no cumple el requisito mínimo de 0.59.\")\n",
    "\n",
    "if auc_roc > auc_roc_initial:\n",
    "     print(\"Se ha mejorado la métrica AUC-ROC con respecto al modelo inicial.\")\n",
    "else:\n",
    "     print(\"No se ha mejorado la métrica AUC-ROC con respecto al modelo inicial.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de este proyecto he tratado de dar solución al problema de Beta Bank con la pérdida de clientes a través del objetivo planteado de lograr un valor F1 superior a 0.59, traté de probar varios métodos para lograr crear el mejor modelo posible para la resolución del problema, pasando por la estructuración de los datos, aplicando métodos para el desequilibrio de clases y obteniendo las mejores métricas para los distintos modelos probados, al final concluí que el mejor modelo en base a los resultados que obtuve y en mi opinión era el random forest desequilibrado con el cual logré satisfacer y superar por poco el requisito principal del valor F1  además de lograr una métrica AUC-ROC mejorada.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1217,
    "start_time": "2024-06-08T02:04:19.035Z"
   },
   {
    "duration": 32,
    "start_time": "2024-06-08T02:04:20.255Z"
   },
   {
    "duration": 70,
    "start_time": "2024-06-08T02:04:22.001Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-08T02:04:25.071Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-08T02:04:26.714Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-08T02:04:27.491Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-08T02:04:29.455Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-08T02:04:30.266Z"
   },
   {
    "duration": 16,
    "start_time": "2024-06-08T02:04:34.615Z"
   },
   {
    "duration": 16,
    "start_time": "2024-06-08T02:04:37.423Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-08T02:04:38.888Z"
   },
   {
    "duration": 13,
    "start_time": "2024-06-08T02:04:41.927Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-08T02:04:44.255Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-08T02:04:48.981Z"
   },
   {
    "duration": 144,
    "start_time": "2024-06-08T02:20:29.175Z"
   },
   {
    "duration": 50,
    "start_time": "2024-06-08T02:20:33.079Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-08T02:20:36.536Z"
   },
   {
    "duration": 80,
    "start_time": "2024-06-08T02:20:38.239Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-08T02:20:41.357Z"
   },
   {
    "duration": 40,
    "start_time": "2024-06-08T02:20:42.762Z"
   },
   {
    "duration": 427,
    "start_time": "2024-06-08T02:27:06.235Z"
   },
   {
    "duration": 1324,
    "start_time": "2024-06-08T02:28:07.978Z"
   },
   {
    "duration": 34,
    "start_time": "2024-06-08T02:28:09.961Z"
   },
   {
    "duration": 72,
    "start_time": "2024-06-08T02:28:11.023Z"
   },
   {
    "duration": 19,
    "start_time": "2024-06-08T02:28:11.435Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-08T02:28:11.958Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-08T02:28:12.514Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-08T02:28:13.435Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-08T02:28:13.995Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-08T02:28:14.519Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-08T02:28:15.548Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-08T02:28:16.028Z"
   },
   {
    "duration": 16,
    "start_time": "2024-06-08T02:28:16.911Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-08T02:28:17.422Z"
   },
   {
    "duration": 14,
    "start_time": "2024-06-08T02:28:18.918Z"
   },
   {
    "duration": 412,
    "start_time": "2024-06-08T02:28:20.711Z"
   },
   {
    "duration": 46,
    "start_time": "2024-06-08T02:28:23.886Z"
   },
   {
    "duration": 21,
    "start_time": "2024-06-08T02:28:25.645Z"
   },
   {
    "duration": 97,
    "start_time": "2024-06-08T02:28:26.312Z"
   },
   {
    "duration": 26,
    "start_time": "2024-06-08T02:28:28.154Z"
   },
   {
    "duration": 36,
    "start_time": "2024-06-08T02:28:28.766Z"
   },
   {
    "duration": 421,
    "start_time": "2024-06-08T02:28:31.244Z"
   },
   {
    "duration": 1733,
    "start_time": "2024-06-08T02:31:07.468Z"
   },
   {
    "duration": 10341,
    "start_time": "2024-06-08T02:33:38.737Z"
   },
   {
    "duration": 1324,
    "start_time": "2024-06-08T02:38:07.065Z"
   },
   {
    "duration": 490,
    "start_time": "2024-06-08T02:40:20.442Z"
   },
   {
    "duration": 998,
    "start_time": "2024-06-08T02:41:42.697Z"
   },
   {
    "duration": 83,
    "start_time": "2024-06-08T02:46:45.873Z"
   },
   {
    "duration": 37,
    "start_time": "2024-06-08T02:50:07.642Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-08T02:51:09.661Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-08T02:52:31.069Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-08T02:55:31.372Z"
   },
   {
    "duration": 1243,
    "start_time": "2024-06-11T20:31:37.583Z"
   },
   {
    "duration": 44,
    "start_time": "2024-06-11T20:31:38.830Z"
   },
   {
    "duration": 71,
    "start_time": "2024-06-11T20:31:40.222Z"
   },
   {
    "duration": 19,
    "start_time": "2024-06-11T20:31:42.080Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-11T20:31:44.078Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-11T20:31:45.423Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-11T20:31:48.222Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-11T20:31:49.037Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-11T20:31:50.882Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-11T20:31:51.786Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-11T20:31:54.772Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-11T20:31:57.172Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-11T20:31:59.640Z"
   },
   {
    "duration": 87,
    "start_time": "2024-06-11T20:32:01.645Z"
   },
   {
    "duration": 48,
    "start_time": "2024-06-11T20:32:07.012Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-11T20:32:10.123Z"
   },
   {
    "duration": 145,
    "start_time": "2024-06-11T20:32:10.860Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-11T20:32:12.798Z"
   },
   {
    "duration": 27,
    "start_time": "2024-06-11T20:32:13.437Z"
   },
   {
    "duration": 433,
    "start_time": "2024-06-11T20:32:16.169Z"
   },
   {
    "duration": 1827,
    "start_time": "2024-06-11T20:32:17.316Z"
   },
   {
    "duration": 11163,
    "start_time": "2024-06-11T20:32:19.146Z"
   },
   {
    "duration": 1411,
    "start_time": "2024-06-11T20:32:30.315Z"
   },
   {
    "duration": 657,
    "start_time": "2024-06-11T20:32:31.730Z"
   },
   {
    "duration": 1059,
    "start_time": "2024-06-11T20:32:32.400Z"
   },
   {
    "duration": 81,
    "start_time": "2024-06-11T20:32:33.463Z"
   },
   {
    "duration": 37,
    "start_time": "2024-06-11T20:32:34.429Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-11T20:32:35.719Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-11T20:32:37.759Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-11T20:32:40.371Z"
   },
   {
    "duration": 22,
    "start_time": "2024-06-11T20:34:49.787Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-11T20:35:57.246Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-11T20:38:33.504Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-11T20:42:25.253Z"
   },
   {
    "duration": 133,
    "start_time": "2024-06-11T20:42:46.083Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-11T20:43:36.962Z"
   },
   {
    "duration": 29,
    "start_time": "2024-06-11T20:43:58.655Z"
   },
   {
    "duration": 495,
    "start_time": "2024-06-11T20:45:32.044Z"
   },
   {
    "duration": 1810,
    "start_time": "2024-06-11T20:46:45.580Z"
   },
   {
    "duration": 1437,
    "start_time": "2024-06-11T20:49:30.705Z"
   },
   {
    "duration": 1372,
    "start_time": "2024-06-11T20:49:43.813Z"
   },
   {
    "duration": 1359,
    "start_time": "2024-06-11T20:50:21.477Z"
   },
   {
    "duration": 533,
    "start_time": "2024-06-11T20:51:58.975Z"
   },
   {
    "duration": 1169,
    "start_time": "2024-06-11T20:54:00.430Z"
   },
   {
    "duration": 72,
    "start_time": "2024-06-11T20:57:31.279Z"
   },
   {
    "duration": 37,
    "start_time": "2024-06-11T20:59:34.164Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-11T20:59:45.100Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-11T20:59:47.546Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-11T21:01:11.776Z"
   },
   {
    "duration": 1256,
    "start_time": "2024-06-11T21:20:05.716Z"
   },
   {
    "duration": 28,
    "start_time": "2024-06-11T21:20:06.975Z"
   },
   {
    "duration": 71,
    "start_time": "2024-06-11T21:20:07.429Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-11T21:20:08.982Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-11T21:20:10.921Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-11T21:20:11.349Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-11T21:20:13.224Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-11T21:20:13.827Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-11T21:20:15.119Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-11T21:20:16.669Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-11T21:20:20.507Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-11T21:20:21.028Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-11T21:20:28.525Z"
   },
   {
    "duration": 190,
    "start_time": "2024-06-11T21:20:31.324Z"
   },
   {
    "duration": 47,
    "start_time": "2024-06-11T21:20:34.324Z"
   },
   {
    "duration": 21,
    "start_time": "2024-06-11T21:20:39.763Z"
   },
   {
    "duration": 57,
    "start_time": "2024-06-11T21:20:40.651Z"
   },
   {
    "duration": 19,
    "start_time": "2024-06-11T21:20:42.479Z"
   },
   {
    "duration": 28,
    "start_time": "2024-06-11T21:20:42.939Z"
   },
   {
    "duration": 392,
    "start_time": "2024-06-11T21:20:54.611Z"
   },
   {
    "duration": 1770,
    "start_time": "2024-06-11T21:20:55.939Z"
   },
   {
    "duration": 9876,
    "start_time": "2024-06-11T21:20:57.713Z"
   },
   {
    "duration": 1353,
    "start_time": "2024-06-11T21:21:07.592Z"
   },
   {
    "duration": 516,
    "start_time": "2024-06-11T21:21:08.949Z"
   },
   {
    "duration": 981,
    "start_time": "2024-06-11T21:21:09.468Z"
   },
   {
    "duration": 85,
    "start_time": "2024-06-11T21:21:10.453Z"
   },
   {
    "duration": 38,
    "start_time": "2024-06-11T21:21:11.844Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-11T21:21:13.527Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-11T21:21:15.125Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-11T21:21:19.049Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
